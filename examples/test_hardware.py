"""
æ¸¬è©¦ç¡¬é«”åµæ¸¬æ¨¡çµ„çš„ç¯„ä¾‹è…³æœ¬
"""

from omnifoundry.core.hardware import HardwareDetector


def main():
    """ä¸»ç¨‹å¼"""
    print("æ­£åœ¨åµæ¸¬ç¡¬é«”è³‡è¨Š...\n")
    
    # å»ºç«‹ç¡¬é«”åµæ¸¬å™¨
    detector = HardwareDetector()
    
    # é¡¯ç¤ºå®Œæ•´ç¡¬é«”è³‡è¨Š
    detector.print_hardware_info()
    
    # æ¸¬è©¦æ¨è–¦é…ç½®åŠŸèƒ½
    print("\n" + "="*60)
    print("ğŸ“‹ æ¨è–¦é…ç½®æ¸¬è©¦")
    print("="*60)
    
    # æ¸¬è©¦ä¸åŒæ¨¡å‹å¤§å°çš„æ¨è–¦é…ç½®
    test_cases = [
        ("llm", "7b", "LLM 7B æ¨¡å‹"),
        ("llm", "13b", "LLM 13B æ¨¡å‹"),
        ("llm", "70b", "LLM 70B æ¨¡å‹"),
        ("diffusion", "sd-1.5", "Stable Diffusion 1.5"),
    ]
    
    for model_type, model_size, description in test_cases:
        print(f"\nã€{description}ã€‘")
        config = detector.recommend_config(model_type=model_type, model_size=model_size)
        
        print(f"  è£ç½®: {config['device']}")
        print(f"  è³‡æ–™å‹åˆ¥: {config['dtype']}")
        print(f"  é‡åŒ–: {config['quantization'] or 'ç„¡'}")
        print(f"  æ‰¹æ¬¡å¤§å°: {config['batch_size']}")
        print(f"  æœ€å¤§é•·åº¦: {config.get('max_length', 'N/A')}")
        print(f"  Flash Attention: {'æ˜¯' if config.get('use_flash_attention') else 'å¦'}")
        print(f"  CPU Offload: {'æ˜¯' if config.get('cpu_offload') else 'å¦'}")
    
    print("\n" + "="*60 + "\n")
    
    # é¡¯ç¤ºåŸå§‹è³‡æ–™ï¼ˆç”¨æ–¼é™¤éŒ¯ï¼‰
    print("\nã€åŸå§‹è³‡æ–™ï¼ˆJSON æ ¼å¼ï¼‰ã€‘")
    import json
    hw_info = detector.get_hardware_info()
    print(json.dumps(hw_info, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    main()

