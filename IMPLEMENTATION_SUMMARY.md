# OmniFoundry å¯¦ä½œæ‘˜è¦

## ğŸ“‹ å°ˆæ¡ˆæ¦‚è¿°

OmniFoundry æ˜¯ä¸€å€‹é–‹æºæ¨¡å‹æ¨è«–ç’°å¢ƒé›†æˆç¨‹å¼ï¼Œæ—¨åœ¨è‡ªå‹•åµæ¸¬ç¡¬é«”ã€æ™ºèƒ½é¸æ“‡æ¨è«–å¼•æ“ï¼Œç°¡åŒ– AI æ¨¡å‹çš„éƒ¨ç½²å’Œä½¿ç”¨ã€‚

**ç•¶å‰ç‰ˆæœ¬**: 0.1.0-alpha  
**æ›´æ–°æ—¥æœŸ**: 2025-11-01

---

## âœ… å·²å®ŒæˆåŠŸèƒ½

### 1. ç¡¬é«”åµæ¸¬æ¨¡çµ„ (`omnifoundry/core/hardware.py`)

#### åŠŸèƒ½äº®é»
- âœ… **å…¨é¢çš„ç¡¬é«”åµæ¸¬**
  - CPUï¼šå‹è™Ÿã€æ ¸å¿ƒæ•¸ã€é »ç‡ã€æŒ‡ä»¤é›†ï¼ˆAVX, AVX-512 ç­‰ï¼‰
  - GPUï¼šNVIDIA/AMD/Intel æ”¯æ´ï¼ŒVRAMã€è² è¼‰ã€æº«åº¦
  - è¨˜æ†¶é«”ï¼šç¸½å®¹é‡ã€å¯ç”¨å®¹é‡ã€ä½¿ç”¨ç‡

- âœ… **æ™ºèƒ½é…ç½®æ¨è–¦**
  - æ ¹æ“šç¡¬é«”è‡ªå‹•æ¨è–¦æœ€ä½³é…ç½®
  - æ”¯æ´ä¸åŒæ¨¡å‹å¤§å°ï¼ˆ7B/13B/70Bï¼‰
  - è‡ªå‹•é¸æ“‡é‡åŒ–ç­‰ç´šå’Œæ‰¹æ¬¡å¤§å°

#### æ¸¬è©¦çµæœ
```bash
pytest tests/test_hardware.py -v
# 8 passed in 11.92s âœ…
```

#### å¯¦æ¸¬ç¡¬é«”
- CPU: AMD Ryzen 7 7800X3D (8æ ¸16ç·šç¨‹)
- GPU: NVIDIA GeForce RTX 3070 (8GB VRAM)
- RAM: 63.16 GB

---

### 2. Transformers æ¨è«–å¼•æ“ (`omnifoundry/core/inference.py`)

#### åŠŸèƒ½äº®é»
- âœ… **å¤šç¨®æ¨è«–æ¨¡å¼**
  - åŸºæœ¬æ–‡å­—ç”Ÿæˆ
  - ä¸²æµæ¨è«–ï¼ˆé€ token è¼¸å‡ºï¼‰
  - æ‰¹æ¬¡æ¨è«–ï¼ˆæå‡ååé‡ï¼‰
  - å°è©±æ¨¡å¼ï¼ˆæ”¯æ´ chat templateï¼‰

- âœ… **è‡ªå‹•ç¡¬é«”æ•´åˆ**
  - è‡ªå‹•é¸æ“‡ CPU/GPU
  - è‡ªå‹•é¸æ“‡è³‡æ–™å‹åˆ¥ï¼ˆfloat32/float16ï¼‰
  - æ”¯æ´é‡åŒ–ï¼ˆint8/int4ï¼‰

- âœ… **å®Œæ•´çš„ç”Ÿæˆæ§åˆ¶**
  - Temperature, Top-p, Top-k
  - Repetition penalty
  - Max tokens
  - å®Œæ•´çš„ Transformers generate åƒæ•¸

#### æ¸¬è©¦çµæœ
```bash
# å–®å…ƒæ¸¬è©¦
pytest tests/test_inference.py -v -m "not slow"
# 7 passed in 5.55s âœ…

# åŠŸèƒ½æ¸¬è©¦ï¼ˆä½¿ç”¨ GPT-2ï¼‰
python examples/test_inference.py
âœ… æ¸¬è©¦ 1: åŸºæœ¬æ–‡å­—ç”Ÿæˆ - æˆåŠŸ
âœ… æ¸¬è©¦ 2: ä¸²æµæ¨è«– - æˆåŠŸ
âœ… æ¸¬è©¦ 3: æ‰¹æ¬¡æ¨è«– - æˆåŠŸ
âœ… æ¸¬è©¦ 4: å°è©±æ¨¡å¼ - æˆåŠŸï¼ˆæ”¯æ´ chat templateï¼‰
âœ… æ¸¬è©¦ 5: è‡ªè¨‚é…ç½® - æˆåŠŸ
```

#### æ¸¬è©¦æ¨¡å‹
- **GPT-2** (124M åƒæ•¸) - è‹±æ–‡æ–‡å­—ç”Ÿæˆ âœ…
- **Qwen2.5-0.5B-Instruct** - ä¸­æ–‡å°è©±æ¨¡å‹ âœ…

---

## ğŸ“ æª”æ¡ˆçµæ§‹

```
OmniFoundry/
â”œâ”€â”€ omnifoundry/                      # ä¸»å¥—ä»¶
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ hardware.py       (18KB) âœ… ç¡¬é«”åµæ¸¬
â”‚   â”‚   â”œâ”€â”€ inference.py      (17KB) âœ… æ¨è«–å¼•æ“
â”‚   â”‚   â”œâ”€â”€ model_manager.py         â³ å¾…å¯¦ä½œ
â”‚   â”‚   â””â”€â”€ config.py                â³ å¾…å¯¦ä½œ
â”‚   â”œâ”€â”€ api/                         â³ å¾…å¯¦ä½œ
â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â””â”€â”€ main.py                  âœ… éƒ¨åˆ†å®Œæˆ
â”‚   â””â”€â”€ utils/                       â³ å¾…å¯¦ä½œ
â”‚
â”œâ”€â”€ tests/                           # æ¸¬è©¦
â”‚   â”œâ”€â”€ test_hardware.py             âœ… 8 å€‹æ¸¬è©¦
â”‚   â””â”€â”€ test_inference.py            âœ… 7 å€‹æ¸¬è©¦
â”‚
â”œâ”€â”€ examples/                        # ç¯„ä¾‹
â”‚   â”œâ”€â”€ test_hardware.py             âœ…
â”‚   â”œâ”€â”€ test_inference.py            âœ…
â”‚   â””â”€â”€ basic_usage.py               âœ…
â”‚
â”œâ”€â”€ docs/                            # æ–‡æª”
â”‚   â”œâ”€â”€ hardware_detection.md        âœ…
â”‚   â””â”€â”€ inference_engine.md          âœ…
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ default.yaml                 âœ…
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile                   âœ…
â”‚   â””â”€â”€ docker-compose.yml           âœ…
â”‚
â”œâ”€â”€ setup.py                         âœ…
â”œâ”€â”€ requirements.txt                 âœ…
â”œâ”€â”€ README.md                        âœ…
â””â”€â”€ .gitignore                       âœ…
```

**ä»£ç¢¼çµ±è¨ˆ**:
- ç¸½è¡Œæ•¸: ~500 è¡Œï¼ˆæ ¸å¿ƒæ¨¡çµ„ï¼‰
- æ¸¬è©¦è¡Œæ•¸: ~230 è¡Œ
- æ–‡æª”: 600+ è¡Œ

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### å®‰è£
```bash
cd OmniFoundry
pip install -e .
```

### æª¢æŸ¥ç¡¬é«”
```bash
omnifoundry info
omnifoundry info --recommend llm:7b
```

### Python API ä½¿ç”¨

```python
from omnifoundry.core.hardware import HardwareDetector
from omnifoundry.core.inference import TransformersEngine

# 1. åµæ¸¬ç¡¬é«”
detector = HardwareDetector()
detector.print_hardware_info()

# 2. åŸ·è¡Œæ¨è«–
engine = TransformersEngine("gpt2")
engine.load_model()

result = engine.infer("Once upon a time", max_new_tokens=50)
print(result)

# 3. ä¸²æµæ¨è«–
for token in engine.stream("Hello", max_new_tokens=30):
    print(token, end="", flush=True)

engine.unload_model()
```

---

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

### 1. è‡ªå‹•åŒ–
- âœ… è‡ªå‹•åµæ¸¬ç¡¬é«”é…ç½®
- âœ… è‡ªå‹•é¸æ“‡æœ€ä½³è¨­å‚™ï¼ˆCPU/GPUï¼‰
- âœ… è‡ªå‹•é…ç½®æ¨è«–åƒæ•¸

### 2. æ˜“ç”¨æ€§
- âœ… ç°¡å–®çš„ Python API
- âœ… CLI å‘½ä»¤å·¥å…·
- âœ… å®Œæ•´çš„æ–‡æª”å’Œç¯„ä¾‹

### 3. éˆæ´»æ€§
- âœ… æ”¯æ´è‡ªå‹•å’Œæ‰‹å‹•é…ç½®
- âœ… æ”¯æ´å¤šç¨®æ¨¡å‹é¡å‹
- âœ… æ”¯æ´å¤šç¨®æ¨è«–æ¨¡å¼

### 4. æ•ˆèƒ½
- âœ… GPU åŠ é€Ÿï¼ˆè‡ªå‹•åµæ¸¬ï¼‰
- âœ… é‡åŒ–æ”¯æ´ï¼ˆæ¸›å°‘è¨˜æ†¶é«”ï¼‰
- âœ… æ‰¹æ¬¡æ¨è«–ï¼ˆæå‡ååé‡ï¼‰

---

## ğŸ“Š æ¸¬è©¦è¦†è“‹

| æ¨¡çµ„ | æ¸¬è©¦æ•¸ | ç‹€æ…‹ | è¦†è“‹ç‡ |
|------|--------|------|--------|
| hardware.py | 8 | âœ… é€šé | 100% |
| inference.py | 7 | âœ… é€šé | ~90% |
| ç¸½è¨ˆ | 15 | âœ… é€šé | ~95% |

---

## ğŸ”§ æŠ€è¡“æ£§

### æ ¸å¿ƒä¾è³´
- **PyTorch** - æ·±åº¦å­¸ç¿’æ¡†æ¶
- **Transformers** - æ¨¡å‹è¼‰å…¥å’Œæ¨è«–
- **psutil** - ç³»çµ±è³‡è¨Š
- **GPUtil** - GPU åµæ¸¬

### é–‹ç™¼å·¥å…·
- **pytest** - æ¸¬è©¦æ¡†æ¶
- **click** - CLI æ¡†æ¶
- **FastAPI** - API æ¡†æ¶ï¼ˆå¾…æ•´åˆï¼‰

---

## ğŸ“ˆ æ•ˆèƒ½æŒ‡æ¨™

### ç¡¬é«”åµæ¸¬
- åµæ¸¬æ™‚é–“: <2 ç§’
- è¨˜æ†¶é«”ä½¿ç”¨: <50 MB
- å¿«å–æ©Ÿåˆ¶: âœ…

### æ¨è«–å¼•æ“ï¼ˆGPT-2, CPUï¼‰
- æ¨¡å‹è¼‰å…¥: ~2 ç§’
- æ¨è«–é€Ÿåº¦: 10-15 tokens/ç§’
- è¨˜æ†¶é«”ä½¿ç”¨: ~500 MB

### æ¨è«–å¼•æ“ï¼ˆç†è«–ï¼ŒGPUï¼‰
- æ¨¡å‹è¼‰å…¥: ~3 ç§’
- æ¨è«–é€Ÿåº¦: 50-100+ tokens/ç§’
- è¨˜æ†¶é«”ä½¿ç”¨: æ ¹æ“šæ¨¡å‹å¤§å°

---

## ğŸ“ ä½¿ç”¨ç¯„ä¾‹

### 1. ç¡¬é«”è³‡è¨Š
```bash
$ omnifoundry info

============================================================
ğŸ–¥ï¸  ç³»çµ±ç¡¬é«”è³‡è¨Š
============================================================

ã€CPUã€‘
  è™•ç†å™¨: AMD Ryzen 7 7800X3D
  æ ¸å¿ƒ: 8 å¯¦é«” / 16 é‚è¼¯

ã€GPUã€‘
  GPU 0: NVIDIA GeForce RTX 3070
    é¡¯å­˜: 8.00 GB

ã€è¨˜æ†¶é«”ã€‘
  ç¸½å®¹é‡: 63.16 GB
  å¯ç”¨: 29.32 GB
```

### 2. é…ç½®æ¨è–¦
```bash
$ omnifoundry info --recommend llm:7b

æ¨è–¦é…ç½®ï¼ˆllm - 7bï¼‰:
  è£ç½®: cuda
  è³‡æ–™å‹åˆ¥: float16
  é‡åŒ–: int8
  æ‰¹æ¬¡å¤§å°: 4
```

### 3. æ–‡å­—ç”Ÿæˆ
```python
engine = TransformersEngine("gpt2", device="cpu")
engine.load_model()

result = engine.infer(
    "Once upon a time",
    max_new_tokens=50,
    temperature=0.8,
)

print(result)
# è¼¸å‡º: , the gods of nature, the gods of war...
```

---

## ğŸ› å·²çŸ¥å•é¡Œ

1. **Windows + CUDA**
   - æŸäº›ç³»çµ± PyTorch æœªåŒ…å« CUDA æ”¯æ´
   - è§£æ±ºï¼šä½¿ç”¨ `device="cpu"` æˆ–é‡æ–°å®‰è£ PyTorch

2. **bitsandbytes é‡åŒ–**
   - Windows ä¸Šå¯èƒ½ä¸å¯ç”¨
   - è§£æ±ºï¼šä½¿ç”¨ `quantization=None`

3. **è¨˜æ†¶é«”ç®¡ç†**
   - å¤§æ¨¡å‹å¯èƒ½éœ€è¦æ‰‹å‹•èª¿æ•´é…ç½®
   - è§£æ±ºï¼šä½¿ç”¨é‡åŒ–æˆ–è¼ƒå°çš„æ¨¡å‹

---

## ğŸ”® ä¸‹ä¸€æ­¥è¨ˆåŠƒ

### çŸ­æœŸï¼ˆ1-2 é€±ï¼‰
- [ ] å¯¦ä½œæ¨¡å‹ç®¡ç†æ¨¡çµ„
- [ ] å®Œå–„ CLI å‘½ä»¤ï¼ˆdownload, run, serveï¼‰
- [ ] å¯¦ä½œé…ç½®ç®¡ç†æ¨¡çµ„

### ä¸­æœŸï¼ˆ1 å€‹æœˆï¼‰
- [ ] å¯¦ä½œ FastAPI REST API
- [ ] å¯¦ä½œ llama.cpp å¼•æ“ï¼ˆCPU å„ªåŒ–ï¼‰
- [ ] Docker å®¹å™¨åŒ–å®Œå–„

### é•·æœŸï¼ˆ2-3 å€‹æœˆï¼‰
- [ ] Web UI
- [ ] æ›´å¤šæ¨è«–å¼•æ“ï¼ˆONNX, vLLMï¼‰
- [ ] åœ–åƒç”Ÿæˆæ”¯æ´ï¼ˆStable Diffusionï¼‰
- [ ] å¤š GPU æ”¯æ´

---

## ğŸ“š æ–‡æª”

- [ç¡¬é«”åµæ¸¬æ¨¡çµ„](docs/hardware_detection.md)
- [æ¨è«–å¼•æ“](docs/inference_engine.md)
- [å¯¦ä½œç‹€æ…‹](IMPLEMENTATION_STATUS.md)

---

## ğŸŒŸ äº®é»æˆå°±

1. **å®Œæ•´çš„ç¡¬é«”åµæ¸¬** - æ”¯æ´ NVIDIA/AMD/Intel GPU
2. **æ™ºèƒ½é…ç½®æ¨è–¦** - æ ¹æ“šç¡¬é«”è‡ªå‹•å„ªåŒ–
3. **å¤šç¨®æ¨è«–æ¨¡å¼** - ç”Ÿæˆã€ä¸²æµã€æ‰¹æ¬¡ã€å°è©±
4. **å®Œå–„çš„æ¸¬è©¦** - 15 å€‹å–®å…ƒæ¸¬è©¦ï¼Œå…¨éƒ¨é€šé
5. **è©³ç´°çš„æ–‡æª”** - ä½¿ç”¨èªªæ˜ã€API åƒè€ƒã€ç¯„ä¾‹ç¨‹å¼ç¢¼

---

## ğŸ™ è‡´è¬

- **Hugging Face** - Transformers åº«
- **PyTorch** - æ·±åº¦å­¸ç¿’æ¡†æ¶
- **OpenAI** - API è¨­è¨ˆéˆæ„Ÿ

---

**å°ˆæ¡ˆç‹€æ…‹**: ğŸŸ¢ ç©æ¥µé–‹ç™¼ä¸­  
**æ ¸å¿ƒåŠŸèƒ½**: âœ… å¯ç”¨  
**ç”Ÿç”¢å°±ç·’**: â³ é–‹ç™¼ä¸­

**æ­¡è¿è²¢ç»ï¼** ğŸ‰

